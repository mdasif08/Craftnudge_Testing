# CraftNudge - Enterprise AI-Powered Git Commit Behavior Tracker

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)

> **Enterprise-grade microservice architecture for AI-powered developer behavior analytics**

## üèóÔ∏è Architecture Overview

```mermaid
graph TB
    subgraph "External Systems"
        GH[GitHub] 
        OLL[Ollama AI]
    end
    
    subgraph "Event-Driven Microservices"
        CT[Commit Tracker<br/>Service]
        AI[AI Analysis<br/>Service]
        CQC[Commit Quality<br/>Coaching Service]
        DB[Database<br/>Service]
        FE[Frontend<br/>Service]
        GW[GitHub Webhook<br/>Service]
    end
    
    subgraph "Infrastructure"
        RB[Redis Event Bus]
        PG[(PostgreSQL)]
        MON[Monitoring]
        LOG[Logging]
    end
    
    GH --> GW
    GW --> RB
    CT --> RB
    RB --> AI
    RB --> CQC
    RB --> DB
    AI --> OLL
    AI --> RB
    CQC --> OLL
    CQC --> RB
    DB --> PG
    FE --> CT
    FE --> DB
    FE --> AI
    FE --> CQC
    
    RB --> MON
    RB --> LOG
```

## üéØ Business Value

- **Developer Productivity**: Track coding patterns and improve commit quality
- **Team Insights**: Understand development behaviors across teams
- **AI-Powered Coaching**: Personalized recommendations for better practices
- **Real-time Analytics**: Immediate feedback on commit patterns
- **Scalable Architecture**: Enterprise-ready microservice design

## üöÄ Quick Start

### Prerequisites

- Python 3.11+
- Docker & Docker Compose
- Ollama (for local AI processing)
- Git repository

### 1. Clone and Setup

```bash
git clone <repository-url>
cd Practice_Mircoservice
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 2. Environment Configuration

```bash
cp .env.example .env
# Edit .env with your configuration
```

### 3. Start Infrastructure

```bash
# Start Redis and PostgreSQL
docker-compose up -d redis postgres

# Start Ollama (if not running)
ollama serve
```

### 4. Initialize Database

```bash
python scripts/init_database.py
```

### 5. Start Services

```bash
# Development mode
python scripts/start_services.py

# Production mode
docker-compose up -d
```

### 6. Access Application

- **Frontend Dashboard**: http://localhost:8000
- **API Documentation**: http://localhost:8000/docs
- **Health Checks**: http://localhost:8000/health

## üìã User Story 2.1.1 Implementation

### Acceptance Criteria ‚úÖ

- ‚úÖ **Commit Tracking**: `commit_tracker.py` logs hash, author, message, timestamp, files
- ‚úÖ **CLI Interface**: `python track_commit.py` for on-demand tracking
- ‚úÖ **Local Storage**: `data/behaviors/commits.jsonl` with structured data
- ‚úÖ **Unique IDs**: UUID-based identification with UTC timestamps
- ‚úÖ **Error Handling**: Graceful failure with user feedback

### Usage Examples

```bash
# Track latest commit
python track_commit.py

# Track commit in specific repository
python track_commit.py --repo-path /path/to/repo

# Show latest commit details
python track_commit.py --show-latest
```

## üéØ Commit Quality Coaching Service

### Overview

The **Commit Quality Coaching Service** provides AI-powered feedback and coaching to help developers improve their commit quality and coding practices. It analyzes commit patterns, provides personalized recommendations, and tracks user progress over time.

### Features

- **AI-Powered Analysis**: Uses Ollama to analyze commit quality based on message clarity, file changes, and code patterns
- **Personalized Feedback**: Generates specific recommendations for improvement
- **Progress Tracking**: Monitors user improvement over time with detailed insights
- **Coaching Sessions**: Interactive coaching with contextual advice
- **Quality Scoring**: 10-point quality assessment with detailed breakdown

### Usage Examples

```bash
# Get coaching feedback for a specific commit
python coach_commit.py --commit-id abc123 --user-id developer1

# View user progress over time
python coach_commit.py progress --user-id developer1 --days 30

# Get AI-generated insights
python coach_commit.py insights --user-id developer1

# Start a coaching session
python coach_commit.py session --user-id developer1
```

### API Endpoints

```bash
# Get coaching feedback
POST /coach/commit
{
  "commit_id": "abc123def456",
  "user_id": "developer1",
  "include_context": true
}

# Get user progress
GET /coach/progress/{user_id}?days=30

# Get coaching insights
GET /coach/insights/{user_id}

# Start coaching session
POST /coach/session/start
{
  "user_id": "developer1",
  "session_type": "commit_quality"
}
```

### Quality Assessment Criteria

| Aspect | Weight | Description |
|--------|--------|-------------|
| **Message Quality** | 40% | Clarity, descriptiveness, conventional format |
| **File Changes** | 30% | Logical grouping, appropriate scope |
| **Code Quality** | 20% | Size, complexity, best practices |
| **Context** | 10% | Historical patterns, team consistency |

### Coaching Feedback Example

```json
{
  "commit_id": "abc123def456",
  "user_id": "developer1",
  "quality_score": 8.5,
  "quality_level": "EXCELLENT",
  "strengths": [
    "Clear and descriptive commit message",
    "Logical file organization",
    "Appropriate commit size"
  ],
  "areas_for_improvement": [
    "Consider adding more context about the business impact",
    "Review test coverage for new functionality"
  ],
  "specific_recommendations": [
    "Use conventional commit format: feat(auth): add OAuth2 authentication",
    "Add integration tests for the new authentication flow"
  ],
  "coaching_tips": [
    "Great job on the descriptive message! Consider mentioning the user story or ticket number.",
    "The commit size is perfect - not too large, not too small."
  ],
  "next_steps": [
    "Review the authentication documentation",
    "Plan follow-up commits for error handling improvements"
  ]
}
```

## üèõÔ∏è Architecture Deep Dive

### Event-Driven Design

```python
# Event Flow Example
CommitEvent ‚Üí Redis ‚Üí AI Analysis ‚Üí Database ‚Üí Frontend
```

### Service Responsibilities

| Service | Port | Responsibility | Dependencies |
|---------|------|----------------|--------------|
| Commit Tracker | 8001 | Git commit capture | Redis, Git |
| AI Analysis | 8002 | Ollama integration | Redis, Ollama |
| Database | 8003 | Data persistence | Redis, PostgreSQL |
| Frontend | 8000 | Web interface | All services |
| GitHub Webhook | 8004 | GitHub integration | Redis |
| Commit Quality Coaching | 8005 | AI-powered coaching | Redis, Ollama |

### Data Flow

1. **Commit Detection**: Manual CLI or GitHub webhook
2. **Event Publishing**: Redis pub/sub for decoupling
3. **AI Processing**: Ollama analysis of commit patterns
4. **Data Storage**: PostgreSQL for persistence
5. **Frontend Display**: Real-time dashboard updates

## üîß Configuration

### Environment Variables

```bash
# Core Application
APP_NAME=CraftNudge
DEBUG=false
LOG_LEVEL=INFO

# Event Bus
REDIS_URL=redis://localhost:6379
REDIS_DB=0

# Database
DATABASE_URL=postgresql://user:pass@localhost:5432/craftnudge

# AI Integration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# GitHub Integration
GITHUB_WEBHOOK_SECRET=your_secret
GITHUB_ACCESS_TOKEN=your_token

# Monitoring
PROMETHEUS_PORT=9090
JAEGER_ENDPOINT=http://localhost:14268
```

### Service Configuration

Each service supports individual configuration:

```yaml
# docker-compose.override.yml
services:
  commit-tracker:
    environment:
      - LOG_LEVEL=DEBUG
      - COMMIT_BATCH_SIZE=10
    volumes:
      - ./config:/app/config
```

## üìä Monitoring & Observability

### Health Checks

```bash
# Service health
curl http://localhost:8001/health
curl http://localhost:8002/health
curl http://localhost:8003/health
curl http://localhost:8004/health
curl http://localhost:8005/health

# System health
curl http://localhost:8000/health
```

### Metrics

- **Prometheus**: http://localhost:9090
- **Grafana**: http://localhost:3000
- **Jaeger**: http://localhost:16686

### Logging

```bash
# View service logs
docker-compose logs -f commit-tracker
docker-compose logs -f ai-analysis

# Centralized logging
docker-compose logs -f elasticsearch kibana
```

## üß™ Testing

### Automated Test Suite

We have implemented a comprehensive automated test suite with **100% code coverage** and **10/10 quality score** requirements.

#### Quick Start

```bash
# Run the comprehensive test suite (recommended)
python run_tests.py

# Or run individual test components
pytest --cov=. --cov-report=term-missing --cov-fail-under=100
```

#### Test Coverage

Our test suite covers:

- **Unit Tests**: All business logic with mocked dependencies
- **Integration Tests**: Service interactions and database operations
- **CLI Tests**: Command-line interface functionality
- **Model Tests**: Pydantic and SQLAlchemy model validation
- **Event System Tests**: Event creation, serialization, and validation
- **Database Tests**: Repository pattern and connection management
- **Configuration Tests**: Settings validation and environment loading

#### Test Files

```
tests/
‚îú‚îÄ‚îÄ test_models.py                  # Data model tests
‚îú‚îÄ‚îÄ test_events.py                  # Event system tests
‚îú‚îÄ‚îÄ test_database.py                # Database layer tests
‚îú‚îÄ‚îÄ test_config_settings.py         # Configuration tests
‚îî‚îÄ‚îÄ test_cli_tools.py               # CLI tool tests

services/
‚îú‚îÄ‚îÄ commit_tracker/tests/
‚îÇ   ‚îî‚îÄ‚îÄ test_main.py                # Commit tracker service tests
‚îî‚îÄ‚îÄ commit_quality_coaching/tests/
    ‚îî‚îÄ‚îÄ test_main.py                # Coaching service tests
```

#### Quality Checks

The test suite includes:

- **Code Coverage**: 100% requirement with detailed reporting
- **Code Linting**: Flake8 with strict standards
- **Type Checking**: MyPy with strict type validation
- **Code Formatting**: Black formatting verification
- **Quality Scoring**: 10/10 quality score requirement

#### Running Specific Tests

```bash
# Run all tests with coverage
pytest --cov=. --cov-report=html --cov-report=term-missing

# Run specific test modules
pytest services/commit_tracker/tests/test_main.py -v
pytest services/commit_quality_coaching/tests/test_main.py -v
pytest tests/test_models.py -v

# Run tests with specific markers
pytest -m unit
pytest -m integration
pytest -m asyncio

# Generate coverage reports
pytest --cov=. --cov-report=html:htmlcov
pytest --cov=. --cov-report=xml:coverage.xml
```

#### Test Results

The test runner generates:

- **Console Output**: Real-time test progress and results
- **HTML Coverage Report**: Detailed coverage analysis in `htmlcov/`
- **XML Coverage Report**: CI/CD integration in `coverage.xml`
- **JSON Results**: Comprehensive test results in `test_results.json`

#### Quality Gates

Tests must pass all quality gates:

- ‚úÖ **100% Code Coverage**: All code paths tested
- ‚úÖ **10/10 Quality Score**: No errors, minimal warnings
- ‚úÖ **All Unit Tests Pass**: Zero test failures
- ‚úÖ **Linting Passes**: Code style compliance
- ‚úÖ **Type Checking Passes**: Type safety validation
- ‚úÖ **Formatting Passes**: Consistent code formatting

#### Continuous Integration

The test suite is designed for CI/CD integration:

```yaml
# Example GitHub Actions workflow
- name: Run Tests
  run: python run_tests.py

- name: Upload Coverage
  uses: codecov/codecov-action@v3
  with:
    file: ./coverage.xml
    fail_ci_if_error: true
```

## üöÄ Deployment

### Development

```bash
# Local development
python infrastructure/start_services.py

# Individual service development
python services/commit_tracker/run.py
python services/commit_quality_coaching/run.py

# CLI tools
python services/commit_tracker/cli.py track
python services/commit_quality_coaching/cli.py coach abc123
```

### Production

```bash
# Docker deployment
docker-compose -f docker-compose.prod.yml up -d

# Kubernetes deployment
kubectl apply -f k8s/
```

### CI/CD Pipeline

```yaml
# .github/workflows/deploy.yml
name: Deploy CraftNudge
on:
  push:
    branches: [main]
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Build and deploy
        run: |
          docker-compose -f docker-compose.prod.yml build
          docker-compose -f docker-compose.prod.yml up -d
```

## üîí Security

### Authentication

- JWT-based authentication for API access
- GitHub OAuth for webhook verification
- Role-based access control (RBAC)

### Data Protection

- Encrypted data at rest
- TLS for all communications
- Regular security audits

### Compliance

- GDPR compliance for user data
- SOC 2 Type II certification ready
- Regular penetration testing

## üìà Performance

### Benchmarks

| Metric | Current | Target |
|--------|---------|--------|
| Commit Processing | 50ms | 25ms |
| AI Analysis | 2s | 1s |
| Database Queries | 10ms | 5ms |
| Event Latency | 5ms | 2ms |

### Optimization

- Redis caching for frequent queries
- Database connection pooling
- Async processing for AI analysis
- Horizontal scaling support

## ü§ù Contributing

### Development Setup

```bash
# Fork and clone
git clone https://github.com/your-username/craftnudge.git
cd craftnudge

# Install development dependencies
pip install -r requirements-dev.txt

# Setup pre-commit hooks
pre-commit install

# Run tests
pytest
```

### Code Standards

- **Python**: Black, isort, flake8
- **Type Hints**: mypy validation
- **Documentation**: Sphinx with autodoc
- **Testing**: pytest with 90%+ coverage

### Pull Request Process

1. Create feature branch
2. Write tests for new functionality
3. Update documentation
4. Ensure all tests pass
5. Submit PR with detailed description

## üìö API Documentation

### REST API

```bash
# OpenAPI documentation
curl http://localhost:8000/openapi.json

# Interactive docs
# Visit http://localhost:8000/docs
```

### Event API

```python
# Publish event
redis_client.publish("commit_events", event.json())

# Subscribe to events
pubsub = redis_client.pubsub()
pubsub.subscribe("commit_events")
```

## üÜò Troubleshooting

### Common Issues

1. **Redis Connection Failed**
   ```bash
   docker-compose up -d redis
   ```

2. **Ollama Not Responding**
   ```bash
   ollama serve
   curl http://localhost:11434/api/tags
   ```

3. **Database Migration Errors**
   ```bash
   python scripts/init_database.py --reset
   ```

### Debug Mode

```bash
# Enable debug logging
export LOG_LEVEL=DEBUG
python scripts/start_services.py
```

### Support

- **Documentation**: [docs.craftnudge.dev](https://docs.craftnudge.dev)
- **Issues**: [GitHub Issues](https://github.com/craftnudge/issues)
- **Discord**: [Community Server](https://discord.gg/craftnudge)

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- **Ollama Team** for local AI processing
- **FastAPI Community** for excellent web framework
- **Redis Team** for event streaming capabilities
- **PostgreSQL Team** for reliable data storage

---

**Built with ‚ù§Ô∏è by the CraftNudge Team**

*Empowering developers to write better code through AI-powered insights*
